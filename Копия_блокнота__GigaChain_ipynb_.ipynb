{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gigachain"
      ],
      "metadata": {
        "id": "b845IWeIK4FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUFgXuWrRKOX"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb --quiet\n",
        "!pip install -U unstructured\n",
        "!pip install unstructured[pdf]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "given_auth_data = \"Yjg4MTQzMmUtNDAwMS00NDk0LThjOGUtNmU5ZWQ2YzQ4NDQ2OmQ4MWMxZGZiLTFmNGYtNDk5NS05OGQzLTBiMzYyYWJmNjk3OA==\""
      ],
      "metadata": {
        "id": "spB_LUK3VHnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import GigaChat\n",
        "from langchain_community.document_loaders import OnlinePDFLoader\n",
        "from langchain.text_splitter import (\n",
        "    RecursiveCharacterTextSplitter,\n",
        ")\n",
        "\n",
        "from chromadb.config import Settings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_community.embeddings.gigachat import GigaChatEmbeddings\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "_44W-tTlBgNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\" # paper url"
      ],
      "metadata": {
        "id": "V2lVi4v4Bo7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_en = \"What kind of problems there are in sequence transduction deep learning models?\"\n",
        "\n",
        "question_ru = \"Какие нерешённые проблемы остались у моделей глубого обучения для обработки последовательностей?\""
      ],
      "metadata": {
        "id": "rNEp1it9ePDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProblemSeekerAgent:\n",
        "  def __init__(self, auth_data):\n",
        "    self.llm = GigaChat(credentials=auth_data, verify_ssl_certs=False, scope='GIGACHAT_API_CORP')\n",
        "    self.embeddings = GigaChatEmbeddings(credentials=auth_data, verify_ssl_certs=False, scope='GIGACHAT_API_CORP')\n",
        "    self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "\n",
        "  def read_article(self, url):\n",
        "    loader = OnlinePDFLoader(url)\n",
        "    documents = loader.load()\n",
        "    documents = self.text_splitter.split_documents(documents)\n",
        "    db = Chroma.from_documents(documents, self.embeddings, client_settings=Settings(anonymized_telemetry=False))\n",
        "    self.db = db\n",
        "\n",
        "  def generate_answer(self, question):\n",
        "    self.qa_chain = RetrievalQA.from_chain_type(self.llm, retriever=self.db.as_retriever())\n",
        "    return self.qa_chain({\"query\": question})['result']"
      ],
      "metadata": {
        "id": "P307si9qi1io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem_seeker = ProblemSeekerAgent(given_auth_data)\n",
        "\n",
        "problem_seeker.read_article(url)\n",
        "\n",
        "answer = problem_seeker.generate_answer(question_ru)\n",
        "\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liN8K2TOq6C9",
        "outputId": "bf6b65a7-198d-4950-f5d1-37ec4ca2f508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "У моделей глубокого обучения для обработки последовательностей осталось несколько нерешенных проблем. Одной из них является ограничение на последовательный характер вычислений, которое делает невозможным параллельное выполнение операций внутри одного примера. Это становится особенно критичным при работе с длинными последовательностями, поскольку ограничения по памяти ограничивают возможность объединения примеров в одну группу для вычислений. Другой проблемой является ограниченная эффективность моделей при обработке зависимостей между элементами, расположенными на большом расстоянии друг от друга. В некоторых моделях, таких как Extended Neural GPU, ByteNet и ConvS2S, количество операций, необходимых для связи сигналов от двух произвольных элементов, увеличивается с увеличением расстояния между ними. Это затрудняет обучение зависимостей между удаленными элементами.\n"
          ]
        }
      ]
    }
  ]
}